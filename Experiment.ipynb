{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # type: ignore\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline, AutoModelForCausalLM\n",
    "import tqdm as notebook_tqdm\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import accelerate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/deepanchakravarthi/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "api_token = \"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\"\n",
    "login(api_token,add_to_git_credential=True)\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/55/ac/55acddbb5c2ac2041b89a858eeba82e6130c6160294d75fe51bfa8bd7a4e4518/d8cf9c4d0dd972e1a2131bfe656235ee98221679711a3beef6d46dadf0f20b5c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00004.safetensors%3B+filename%3D%22model-00001-of-00004.safetensors%22%3B&Expires=1721212579&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMTIxMjU3OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU1L2FjLzU1YWNkZGJiNWMyYWMyMDQxYjg5YTg1OGVlYmE4MmU2MTMwYzYxNjAyOTRkNzVmZTUxYmZhOGJkN2E0ZTQ1MTgvZDhjZjljNGQwZGQ5NzJlMWEyMTMxYmZlNjU2MjM1ZWU5ODIyMTY3OTcxMWEzYmVlZjZkNDZkYWRmMGYyMGI1Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=DRx9LLWhOAiMivdc-DhwhVt8wKvyvY7Xk4sQQLhj-72QXa6fPrYSkDmOZupsYPpBlGqTiB5XeLXiL9-ji7E8A7Ha5r7RT36tXQHIwyZiU%7E5Rf60UbnsCbz5nyp0FYmUQiy4sYSUQS426og4aHoN0kdDmfmPzPyBSOFibXTCeY3ozLWnRylXqC1CXcCsTITa97%7EDWVYj6D8cJsw47Q4ZAknbTbaVoHMIfm3TiT-hHr8wrj1SjpmVUnG8D-Sxdllz2SyGhMI-1rmBGmbLKiX4owznDwDy7ZIbzZVzh5txzYkM6bz8iZVhIdA3v-6gsTcU6mTE6-Ssor5poocFDK0QHmw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Downloading shards:  25%|██▌       | 1/4 [48:00<2:24:01, 2880.40s/it]"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/deepanchakravarthi/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "api_token = \"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\"\n",
    "login(api_token,add_to_git_credential=True)\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chat history JSON file\n",
    "with open('./data/chat_history.json', 'r') as file:\n",
    "    chat_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customer_id': 'C001',\n",
       "  'chat_history': [{'timestamp': '2024-07-01T10:00:00Z',\n",
       "    'message': \"Hi, I'm looking for a summer dress.\"},\n",
       "   {'timestamp': '2024-07-01T10:01:00Z',\n",
       "    'message': 'Do you have anything in yellow?'},\n",
       "   {'timestamp': '2024-07-01T10:02:00Z',\n",
       "    'agent_message': 'Hello! Yes, we have a few options. Would you like a casual or formal dress?'},\n",
       "   {'timestamp': '2024-07-01T10:03:00Z', 'message': 'A casual dress, please.'},\n",
       "   {'timestamp': '2024-07-01T10:04:00Z',\n",
       "    'agent_message': 'Great! Here are a few yellow casual dresses. [Link to products]'}]},\n",
       " {'customer_id': 'C002',\n",
       "  'chat_history': [{'timestamp': '2024-07-02T14:20:00Z',\n",
       "    'message': 'Hello, do you have size 8 in black jeans?'},\n",
       "   {'timestamp': '2024-07-02T14:21:00Z',\n",
       "    'agent_message': 'Hi! Let me check that for you.'},\n",
       "   {'timestamp': '2024-07-02T14:22:00Z',\n",
       "    'agent_message': 'Yes, we have size 8 in stock for black jeans. [Link to product]'},\n",
       "   {'timestamp': '2024-07-02T14:23:00Z',\n",
       "    'message': 'Thank you! Can I place an order here?'},\n",
       "   {'timestamp': '2024-07-02T14:24:00Z',\n",
       "    'agent_message': \"Sure! I'll assist you with placing the order.\"}]},\n",
       " {'customer_id': 'C003',\n",
       "  'chat_history': [{'timestamp': '2024-07-03T09:15:00Z',\n",
       "    'message': 'Hi, can you recommend a jacket for cold weather?'},\n",
       "   {'timestamp': '2024-07-03T09:16:00Z',\n",
       "    'agent_message': 'Hello! Of course. Do you have a preference for style or color?'},\n",
       "   {'timestamp': '2024-07-03T09:17:00Z',\n",
       "    'message': 'Something stylish and in blue, please.'},\n",
       "   {'timestamp': '2024-07-03T09:18:00Z',\n",
       "    'agent_message': 'We have several stylish blue jackets. Here are some options. [Link to products]'},\n",
       "   {'timestamp': '2024-07-03T09:19:00Z',\n",
       "    'message': 'These look great, thank you!'}]},\n",
       " {'customer_id': 'C004',\n",
       "  'chat_history': [{'timestamp': '2024-07-04T11:30:00Z',\n",
       "    'message': \"Hello, I'm looking for a gift for my wife. Any suggestions?\"},\n",
       "   {'timestamp': '2024-07-04T11:31:00Z',\n",
       "    'agent_message': 'Hi! Sure, can you tell me a bit about her style?'},\n",
       "   {'timestamp': '2024-07-04T11:32:00Z',\n",
       "    'message': 'She loves elegant dresses.'},\n",
       "   {'timestamp': '2024-07-04T11:33:00Z',\n",
       "    'agent_message': 'We have some beautiful elegant dresses that would make a perfect gift. [Link to products]'},\n",
       "   {'timestamp': '2024-07-04T11:34:00Z',\n",
       "    'message': \"Thank you, I'll check these out.\"}]},\n",
       " {'customer_id': 'C005',\n",
       "  'chat_history': [{'timestamp': '2024-07-05T16:45:00Z',\n",
       "    'message': 'Hi, do you have any promotions or discounts available?'},\n",
       "   {'timestamp': '2024-07-05T16:46:00Z',\n",
       "    'agent_message': 'Hello! Yes, we currently have a 20% discount on all summer wear.'},\n",
       "   {'timestamp': '2024-07-05T16:47:00Z',\n",
       "    'message': \"That's great! How can I apply the discount?\"},\n",
       "   {'timestamp': '2024-07-05T16:48:00Z',\n",
       "    'agent_message': 'You can use the code SUMMER20 at checkout to avail the discount.'},\n",
       "   {'timestamp': '2024-07-05T16:49:00Z', 'message': 'Thank you!'}]}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cleaned text to chat_data \n",
    "for customer in chat_data:\n",
    "    for message in customer['chat_history']:\n",
    "        if 'message' in message:\n",
    "            message['cleaned_text'] = clean_text(message['message'])\n",
    "        elif 'agent_message' in message:\n",
    "            message['cleaned_text'] = clean_text(message['agent_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling\n",
    "all_texts = [message['cleaned_text'] for customer in chat_data for message in customer['chat_history'] if 'cleaned_text' in message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(all_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.components_[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topics(lda, vectorizer.get_feature_names_out(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
